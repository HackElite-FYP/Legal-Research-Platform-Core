{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model training completed successfully using array-based dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Install required libraries\n",
    "# %pip install matplotlib seaborn\n",
    "\n",
    "# Step 2: Import Required Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 3: Load Training Dataset from JSON\n",
    "import json\n",
    "\n",
    "with open('resources/training_data.json', 'r') as f:\n",
    "    training_data = json.load(f)\n",
    "\n",
    "# Step 4: Convert to DataFrame\n",
    "df = pd.DataFrame(training_data['training_data'])\n",
    "\n",
    "# Step 5: Split Dataset (optional for testing accuracy, skipping here)\n",
    "X = df[\"text\"]\n",
    "y = df[\"type\"]\n",
    "\n",
    "# Step 6: Build the Model Pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=1000, ngram_range=(1,2))),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='auto'))\n",
    "])\n",
    "\n",
    "# Step 7: Train the Model\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "print(\"✅ Model training completed successfully using array-based dataset.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [23, 18]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClassification Report:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Step 9: Confusion Matrix\u001b[39;00m\n\u001b[32m     49\u001b[39m cm = confusion_matrix(y_test, y_pred, labels=pipeline.classes_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2671\u001b[39m, in \u001b[36mclassification_report\u001b[39m\u001b[34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[32m   2564\u001b[39m \n\u001b[32m   2565\u001b[39m \u001b[33;03mRead more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2667\u001b[39m \u001b[33;03m<BLANKLINE>\u001b[39;00m\n\u001b[32m   2668\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2670\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m-> \u001b[39m\u001b[32m2671\u001b[39m y_type, y_true, y_pred = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2674\u001b[39m     labels = unique_labels(y_true, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[32m     72\u001b[39m \n\u001b[32m     73\u001b[39m \u001b[33;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     97\u001b[39m xp, _ = get_namespace(y_true, y_pred)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m type_true = type_of_target(y_true, input_name=\u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    100\u001b[39m type_pred = type_of_target(y_pred, input_name=\u001b[33m\"\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [23, 18]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6: Predict on Test Set using extracted dataset\n",
    "\n",
    "# X_test → Extracted Texts from the new document\n",
    "# y_test → Corresponding Labels from the new document\n",
    "# test case:\"id\": \"6c3ba11d-1d4c-4213-8560-ea1b6d4a035e\",\n",
    "X_test = [\n",
    "    \"The Governor acted within his discretionary executive authority under Article 154C of the Constitution when interdicting the Petitioner.\",\n",
    "    \"The interdiction and initiation of a preliminary inquiry by the Governor were justified under the constitutional and statutory framework during the absence of a functioning Provincial Council.\",\n",
    "    \"The Court does not have jurisdiction to interpret the Constitution under Article 125; such power lies solely with the Supreme Court.\",\n",
    "    \"Challenging the charge sheet on the basis that it was issued by the Governor is erroneous, as it was issued under the authority of the Board of Management.\",\n",
    "\n",
    "\n",
    "    \"The Southern Provincial Council was dissolved on 01.04.2019, and the Office of the Chief Minister became defunct.\",\n",
    "    \"There was no functioning Board of Management or subject Minister to take disciplinary action regarding the SPDA.\",\n",
    "    \"An internal audit report (R1) indicated the Petitioner had committed serious financial misconduct and violated financial regulations.\",\n",
    "    \"The Governor, under Article 154C and 154F and Section 27A of the Provincial Councils Act, holds residual executive power to ensure uninterrupted administration when the Provincial Council ceases to function.\",\n",
    "    \"Article 154B(11) allows the Governor to call for information relating to provincial administration, which supports supervisory authority.\",\n",
    "    \"Section 24 of the SPDA Statute No. 01 of 1995 normally vests disciplinary power in the Board of Management, but that Board was non-existent due to the council’s dissolution.\",\n",
    "    \"The marking scheme P10 received by the Petitioner was a brief version, whereas R4 was a detailed scheme.\",\n",
    "    \"The Governor relied on the audit report findings to direct a preliminary inquiry and issue the letter of interdiction.\",\n",
    "\n",
    "\n",
    "    \"Names and addresses of the Petitioner and 16 Respondents, including SPDA Board members, former and current Governors.\",\n",
    "    \"Counsel: Sanjeewa Jayawardane PC for the Petitioner; Saman Galapaththi and Manohara Jayasinghe DSG for the Respondents.\",\n",
    "    \"Case procedural info: Argued on 13.06.2023, submissions filed on 24.12.2023 and 26.09.2023, decided on 09.01.2024.\",\n",
    "    \"Excerpts and reproductions of constitutional provisions (Articles 154B, 154C, 154F, and 125) and Provincial Councils Act Section 27A.\",\n",
    "    \"Judges: M.T. Mohammed Laffar, J. and S.U.B. Karalliyadde, J.\",\n",
    "    \"Procedural description of writs requested: Certiorari, Mandamus, Prohibition (total of 10 reliefs prayed for).\"\n",
    "]\n",
    "\n",
    "y_test = [\n",
    "    \"Claim\", \"Claim\", \"Claim\", \"Claim\", \n",
    "    \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\", \"Premise\",\n",
    "    \"Non-Argumentative\", \"Non-Argumentative\", \"Non-Argumentative\", \"Non-Argumentative\", \"Non-Argumentative\", \"Non-Argumentative\"\n",
    "]\n",
    "\n",
    "# Step 7: Predict\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Step 9: Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=pipeline.classes_)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\", xticklabels=pipeline.classes_, yticklabels=pipeline.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 10: Optional Display Predictions\n",
    "print(\"\\n Individual Predictions:\")\n",
    "for sentence, pred in zip(X_test, y_pred):\n",
    "    print(f\"➡ \\\"{sentence[:80]}...\\\" ➝ Predicted: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-label Classification\n",
    "# Step 1: Install dependencies\n",
    "%pip install -q sentence-transformers scikit-learn pandas\n",
    "\n",
    "# Step 2: Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Step 3: Sample Multi-label Data (You can replace this with your real dataset later)\n",
    "data = {\n",
    "    \"sentence\": [\n",
    "        \"According to Section 21, the rule applies.\",\n",
    "        \"Because the defendant was not present at the scene.\",\n",
    "        \"The court believes the plaintiff acted in good faith.\",\n",
    "        \"However, the plaintiff's claim contradicts the evidence.\",\n",
    "        \"The judge finally ordered compensation to the tenant.\"\n",
    "    ],\n",
    "    \"labels\": [\n",
    "        [\"Legal Principle\"],\n",
    "        [\"Factual Evidence\"],\n",
    "        [\"Factual Evidence\", \"Judgment\"],\n",
    "        [\"Counter-Argument\"],\n",
    "        [\"Judgment\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 4: Binarize the multi-labels\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df['labels'])\n",
    "\n",
    "# Step 5: Load Sentence-BERT or LegalBERT embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # You can replace with LegalBERT if needed\n",
    "X = model.encode(df['sentence'].tolist())\n",
    "\n",
    "# Step 6: Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 7: Train Multi-label Classifier (Logistic Regression with sigmoid)\n",
    "classifier = MultiOutputClassifier(LogisticRegression())\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Predict and Evaluate\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Classification Report (per label):\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=mlb.classes_))\n",
    "\n",
    "# Step 9: Predict new sentence\n",
    "new_sentence = [\"The defendant violated the law according to Section 5.\"]\n",
    "new_embed = model.encode(new_sentence)\n",
    "predicted_labels = mlb.inverse_transform(classifier.predict(new_embed))\n",
    "print(\"\\nPredicted Argument Type(s):\", predicted_labels[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
