{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5ce6a82d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ce6a82d",
        "outputId": "878304ef-789c-455b-de1c-ef14bfcef6ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.1)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.1)\n",
            "Requirement already satisfied: seaborn in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: accelerate in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.9.0)\n",
            "Requirement already satisfied: transformers[torch] in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.53.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2.2.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from transformers[torch]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers[torch]) (2.7.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.1->transformers[torch]) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.1->transformers[torch]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.1->transformers[torch]) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=2.1->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=2.1->transformers[torch]) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers[torch]) (2025.1.31)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers[torch] pandas scikit-learn matplotlib seaborn accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "266e24b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "266e24b9",
        "outputId": "804cb0b4-c235-4c1c-9797-38645fcef4ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.53.2)\n",
            "Requirement already satisfied: accelerate in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.9.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.2.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.7.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eb9a0f99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb9a0f99",
        "outputId": "c76dcfa7-0e0f-4c21-8825-03cf05f146ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (25.1.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3770eedc",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fa1af7a8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Attempting to load data from: resources/training_data.json\n",
            "Data loaded and parsed successfully!\n",
            "\n",
            "--- Data Overview ---\n",
            "Original label distribution:\n",
            "label\n",
            "Premise              117\n",
            "Claim                 79\n",
            "Non-Argumentative     45\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Preparing Data for Model ---\n",
            "\n",
            "--- Loading roberta-large model and tokenizer ---\n",
            "\n",
            "--- Initializing RoBERTa-large Model ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Starting Model Training ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 200\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Starting Model Training ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Training Finished ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2206\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2204\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2207\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2548\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2541\u001b[39m context = (\n\u001b[32m   2542\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2543\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2544\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2545\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2546\u001b[39m )\n\u001b[32m   2547\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2548\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2551\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2552\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2553\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2554\u001b[39m ):\n\u001b[32m   2555\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2556\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3797\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   3795\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3797\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3799\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\accelerator.py:2578\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2576\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2577\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2578\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\function.py:307\u001b[39m, in \u001b[36mBackwardCFunction.apply\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    302\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mImplementing both \u001b[39m\u001b[33m'\u001b[39m\u001b[33mbackward\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mvjp\u001b[39m\u001b[33m'\u001b[39m\u001b[33m for a custom \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    303\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFunction is not allowed. You should only implement one \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    304\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mof them.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    305\u001b[39m     )\n\u001b[32m    306\u001b[39m user_fn = vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function.vjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\checkpoint.py:320\u001b[39m, in \u001b[36mCheckpointFunction.backward\u001b[39m\u001b[34m(ctx, *args)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs_with_grad) == \u001b[32m0\u001b[39m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    317\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnone of output has requires_grad=True,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    318\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m this checkpoint() is not necessary\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    319\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs_with_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_with_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m grads = \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m    322\u001b[39m     inp.grad \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inp, torch.Tensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m detached_inputs\n\u001b[32m    324\u001b[39m )\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) + grads\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Step 0: Install required packages\n",
        "%pip install -q pandas numpy scikit-learn transformers[torch] datasets matplotlib seaborn\n",
        "\n",
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Step 2: Data Loading Function\n",
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Load data from a JSON file.\n",
        "    \"\"\"\n",
        "    print(f\"Attempting to load data from: {file_path}\")\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Error: File not found at '{file_path}'\")\n",
        "        print(\"Creating a dummy 'resources/training_data.json' for demonstration.\")\n",
        "        os.makedirs('resources', exist_ok=True)\n",
        "        dummy_data = {\n",
        "            \"training_data\": [\n",
        "                {\"text\": \"The first claim is valid.\", \"type\": \"Claim\"},\n",
        "                {\"text\": \"The second claim is also valid.\", \"type\": \"Claim\"},\n",
        "                {\"text\": \"The first premise is a fact.\", \"type\": \"Premise\"},\n",
        "                {\"text\": \"The second premise is an opinion.\", \"type\": \"Premise\"},\n",
        "                {\"text\": \"This sentence is just background info.\", \"type\": \"Non-Argumentative\"}\n",
        "            ]\n",
        "        }\n",
        "        with open(file_path, 'w') as f:\n",
        "            json.dump(dummy_data, f, indent=2)\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f: \n",
        "            data = json.load(f)\n",
        "        if isinstance(data, dict):\n",
        "            for key in ['training_data', 'data', 'records']:\n",
        "                if key in data and isinstance(data[key], list): \n",
        "                    records = data[key]\n",
        "                    break\n",
        "            else: \n",
        "                raise ValueError(\"JSON is a dict but no list key was found.\")\n",
        "        elif isinstance(data, list): \n",
        "            records = data\n",
        "        else: \n",
        "            raise TypeError(\"Unsupported JSON format.\")\n",
        "\n",
        "        df = pd.DataFrame(records)\n",
        "        if 'type' in df.columns: \n",
        "            df.rename(columns={'type': 'label'}, inplace=True)\n",
        "        if not all(col in df.columns for col in ['text', 'label']): \n",
        "            raise ValueError(\"Records must contain 'text' and 'type'/'label' keys.\")\n",
        "        print(\"Data loaded and parsed successfully!\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading or processing data: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Step 3: Main Execution Block\n",
        "file_path = 'resources/training_data.json'\n",
        "df = load_data(file_path)\n",
        "\n",
        "if df is not None and not df.empty:\n",
        "    print(\"\\n--- Data Overview ---\")\n",
        "    print(\"Original label distribution:\")\n",
        "    print(df['label'].value_counts())\n",
        "\n",
        "    # Handle classes with only one member\n",
        "    label_counts = df['label'].value_counts()\n",
        "    minority_classes = label_counts[label_counts < 2].index.tolist()\n",
        "\n",
        "    if minority_classes:\n",
        "        print(f\"\\nWarning: The following classes have only 1 sample: {minority_classes}\")\n",
        "        print(\"Duplicating these samples to allow for stratified splitting.\")\n",
        "\n",
        "        records_to_add = []\n",
        "        for cls in minority_classes:\n",
        "            records_to_add.append(df[df['label'] == cls].iloc[0])\n",
        "\n",
        "        df = pd.concat([df] + [pd.DataFrame([rec]) for rec in records_to_add], ignore_index=True)\n",
        "\n",
        "        print(\"\\nNew label distribution after duplication:\")\n",
        "        print(df['label'].value_counts())\n",
        "\n",
        "    # Data Preparation\n",
        "    print(\"\\n--- Preparing Data for Model ---\")\n",
        "    labels = sorted(df['label'].unique().tolist())\n",
        "    label_to_id = {label: i for i, label in enumerate(labels)}\n",
        "    id_to_label = {i: label for label, i in label_to_id.items()}\n",
        "    df['label_id'] = df['label'].map(label_to_id)\n",
        "\n",
        "    # Split data\n",
        "    train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "        df['text'].tolist(), \n",
        "        df['label_id'].tolist(), \n",
        "        test_size=0.2, \n",
        "        random_state=42, \n",
        "        stratify=df['label_id']\n",
        "    )\n",
        "\n",
        "    # Use RoBERTa-large\n",
        "    model_name = \"roberta-large\"\n",
        "    print(f\"\\n--- Loading {model_name} model and tokenizer ---\")\n",
        "    \n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    \n",
        "    # Tokenize datasets\n",
        "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=256)\n",
        "    test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=256)\n",
        "\n",
        "    class LegalDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, encodings, labels):\n",
        "            self.encodings = encodings\n",
        "            self.labels = labels\n",
        "        \n",
        "        def __getitem__(self, idx):\n",
        "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "            return item\n",
        "        \n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "    train_dataset = LegalDataset(train_encodings, train_labels)\n",
        "    test_dataset = LegalDataset(test_encodings, test_labels)\n",
        "\n",
        "    # Initialize model with gradient checkpointing\n",
        "    print(\"\\n--- Initializing RoBERTa-large Model ---\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name, \n",
        "        num_labels=len(id_to_label), \n",
        "        id2label=id_to_label, \n",
        "        label2id=label_to_id,\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "    \n",
        "    # Enable gradient checkpointing to save memory\n",
        "    model.gradient_checkpointing_enable()\n",
        "\n",
        "    # Metrics function\n",
        "    def compute_metrics(pred):\n",
        "        labels = pred.label_ids\n",
        "        preds = pred.predictions.argmax(-1)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            labels, preds, average='weighted', zero_division=0\n",
        "        )\n",
        "        acc = accuracy_score(labels, preds)\n",
        "        return {\n",
        "            'accuracy': acc, \n",
        "            'f1': f1, \n",
        "            'precision': precision, \n",
        "            'recall': recall\n",
        "        }\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./results',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=4,  # Reduced for RoBERTa-large\n",
        "        per_device_eval_batch_size=8,\n",
        "        warmup_steps=100,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=10,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=100,\n",
        "        save_strategy=\"steps\",\n",
        "        save_steps=100,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True,\n",
        "        seed=42,\n",
        "        fp16=True,  # Enable mixed precision\n",
        "        gradient_accumulation_steps=2,  # Helps with batch size\n",
        "        report_to=\"none\"  # Disable external reporting\n",
        "    )\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    print(\"\\n--- Starting Model Training ---\")\n",
        "    trainer.train()\n",
        "    print(\"\\n--- Training Finished ---\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(\"\\n--- Final Evaluation on Test Set ---\")\n",
        "    eval_results = trainer.evaluate()\n",
        "    print(eval_results)\n",
        "\n",
        "    # Save the model and tokenizer\n",
        "    output_dir = \"./legal_argument_model_roberta\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    trainer.save_model(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    print(f\"\\nModel and tokenizer saved to {output_dir}\")\n",
        "\n",
        "    # Function to make predictions\n",
        "    def predict(text, model_path, tokenizer_path):\n",
        "        # Load model and tokenizer\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "        \n",
        "        # Tokenize input\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
        "        \n",
        "        # Get predictions\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        \n",
        "        # Get predicted class\n",
        "        predicted_class_id = torch.argmax(outputs.logits, dim=1).item()\n",
        "        return model.config.id2label[predicted_class_id]\n",
        "\n",
        "    # Example prediction\n",
        "    example_text = \"The defendant's actions were clearly in violation of the contract terms.\"\n",
        "    predicted_label = predict(example_text, output_dir, output_dir)\n",
        "    print(f\"\\n--- Example Prediction ---\")\n",
        "    print(f\"Text: '{example_text}'\")\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n",
        "\n",
        "    # Generate and plot confusion matrix\n",
        "    print(\"\\n--- Generating Confusion Matrix ---\")\n",
        "    predictions = trainer.predict(test_dataset)\n",
        "    y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "    y_true = predictions.label_ids\n",
        "    \n",
        "    # Get class names from id_to_label\n",
        "    class_names = [id_to_label[i] for i in sorted(id_to_label.keys())]\n",
        "    \n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=class_names, \n",
        "                yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "    \n",
        "    # Print classification report\n",
        "    from sklearn.metrics import classification_report\n",
        "    print(\"\\n--- Classification Report ---\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "DmCBxefDTsz-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmCBxefDTsz-",
        "outputId": "bdd92359-eba8-44df-8fc2-ab35f06f757d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
